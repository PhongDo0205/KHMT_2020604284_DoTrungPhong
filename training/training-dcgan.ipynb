{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3885455,"sourceType":"datasetVersion","datasetId":2308795},{"sourceId":4202543,"sourceType":"datasetVersion","datasetId":2477766},{"sourceId":8234968,"sourceType":"datasetVersion","datasetId":4884209},{"sourceId":8421784,"sourceType":"datasetVersion","datasetId":5013911},{"sourceId":49188,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":41102},{"sourceId":49203,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":41111}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# data_dir=\"../input/data-art/data_train\"","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:20:13.360727Z","iopub.execute_input":"2024-05-18T03:20:13.361818Z","iopub.status.idle":"2024-05-18T03:20:13.368308Z","shell.execute_reply.started":"2024-05-18T03:20:13.361782Z","shell.execute_reply":"2024-05-18T03:20:13.367034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir=\"../input/portrait-painting/portrait_painting\"","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:20:13.370977Z","iopub.execute_input":"2024-05-18T03:20:13.371395Z","iopub.status.idle":"2024-05-18T03:20:13.383949Z","shell.execute_reply.started":"2024-05-18T03:20:13.371367Z","shell.execute_reply":"2024-05-18T03:20:13.383065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_dir=\"/kaggle/working/datatrain\"","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:20:13.386340Z","iopub.execute_input":"2024-05-18T03:20:13.386695Z","iopub.status.idle":"2024-05-18T03:20:13.394454Z","shell.execute_reply.started":"2024-05-18T03:20:13.386658Z","shell.execute_reply":"2024-05-18T03:20:13.392750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_dir = \"/kaggle/working/Output\"","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:20:13.395805Z","iopub.execute_input":"2024-05-18T03:20:13.396178Z","iopub.status.idle":"2024-05-18T03:20:13.407177Z","shell.execute_reply.started":"2024-05-18T03:20:13.396152Z","shell.execute_reply":"2024-05-18T03:20:13.405964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom keras.models import Sequential, Model, load_model\nfrom keras.layers import Input, Dense, Reshape, Flatten, Activation\nfrom keras.layers import ReLU, LeakyReLU, BatchNormalization\nfrom keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\nfrom keras.optimizers import Adam\nfrom keras.initializers import RandomNormal\n\nfrom IPython import display\nfrom PIL import Image\nimport h5py","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:20:13.408742Z","iopub.execute_input":"2024-05-18T03:20:13.409035Z","iopub.status.idle":"2024-05-18T03:20:26.448980Z","shell.execute_reply.started":"2024-05-18T03:20:13.409011Z","shell.execute_reply":"2024-05-18T03:20:26.448030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:20:26.451961Z","iopub.execute_input":"2024-05-18T03:20:26.452982Z","iopub.status.idle":"2024-05-18T03:20:26.457645Z","shell.execute_reply.started":"2024-05-18T03:20:26.452944Z","shell.execute_reply":"2024-05-18T03:20:26.456643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preview image Frame\nPREVIEW_ROWS = 4\nPREVIEW_COLS = 7\nPREVIEW_MARGIN = 4\n\nIMAGE_CHANNELS = 3\n\n\nSEED_SIZE = 100\n\nIMG_SIZE = 64\nNOISE_DIM = 100\nBATCH_SIZE = 64\nEPOCHS = 200\nSAVE_FREQ = 20\n\ncross_entropy = tf.keras.losses.BinaryCrossentropy()","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:20:26.459030Z","iopub.execute_input":"2024-05-18T03:20:26.459405Z","iopub.status.idle":"2024-05-18T03:20:26.483084Z","shell.execute_reply.started":"2024-05-18T03:20:26.459370Z","shell.execute_reply":"2024-05-18T03:20:26.482077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# images_path = data_dir \n# training_data = []\n\n# # Iterating over the images inside the directory and resizing them using\n# # Pillow's resize method.\n# print('resizing...')\n\n# for filename in os.listdir(images_path):\n#     path = os.path.join(images_path, filename)\n#     image = Image.open(path).resize((IMG_SIZE, IMG_SIZE), Image.Resampling.LANCZOS)\n    \n#     training_data.append(np.asarray(image))\n\n# # training_data = (training_data - 127.5) / 127.5\n\n# print('saving file...')\n# os.makedirs(input_dir, exist_ok=True)\n# np.save(os.path.join(input_dir, 'training_data.npy'), training_data)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:20:26.484415Z","iopub.execute_input":"2024-05-18T03:20:26.484802Z","iopub.status.idle":"2024-05-18T03:20:26.492964Z","shell.execute_reply.started":"2024-05-18T03:20:26.484767Z","shell.execute_reply":"2024-05-18T03:20:26.492009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_data = []\n\n\n# Look for saved file to save time loading and processing images between runs\nprint(\"Looking for saved binary file...\")\n\nif not os.path.isfile(os.path.join(input_dir, 'training_data.npy')):\n    print(\"\\n File not found, creating new file...\\n\")\n    print('resizing...')\n    \n    for filename in os.listdir(data_dir):\n        image_path = os.path.join(data_dir, filename)\n        if os.path.isfile(image_path):\n            image = Image.open(image_path).resize((IMG_SIZE, IMG_SIZE), Image.Resampling.LANCZOS)\n            image_array = np.array(image)\n            training_data.append(image_array)\n\n    training_data = np.array(training_data, dtype=np.float32)\n    training_data = (training_data - 127.5) / 127.5 # Normalize to [-1 , 1]\n\n    print(\"Saving dataset binary file...\")\n    os.makedirs(input_dir, exist_ok=True)\n    np.save(os.path.join(input_dir, 'training_data.npy'), training_data)  # Save processed images as npy file\nelse:\n    print(\"Data found, loading..\")\n    training_data = np.load(os.path.join(input_dir, 'training_data.npy'))\n\nprint(\"Dataset length: \", len(training_data))","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:20:26.494205Z","iopub.execute_input":"2024-05-18T03:20:26.494820Z","iopub.status.idle":"2024-05-18T03:21:52.707248Z","shell.execute_reply.started":"2024-05-18T03:20:26.494788Z","shell.execute_reply":"2024-05-18T03:21:52.706300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training_data = np.load(os.path.join(input_dir, 'training_data.npy'))","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:21:52.708916Z","iopub.execute_input":"2024-05-18T03:21:52.709296Z","iopub.status.idle":"2024-05-18T03:21:52.713759Z","shell.execute_reply.started":"2024-05-18T03:21:52.709263Z","shell.execute_reply":"2024-05-18T03:21:52.712643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# images_path = data_dir\n# training_data = []\n# for filename in os.listdir(images_path):\n#     path = os.path.join(images_path, filename)\n#     image = Image.open(path).resize((IMG_SIZE, IMG_SIZE), Image.Resampling.LANCZOS)\n#     training_data.append(np.asarray(image))\n# training_data = np.reshape(training_data, (-1, IMG_SIZE, IMG_SIZE, IMAGE_CHANNELS))\n# training_data = training_data / 127.5 - 1","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:21:52.715342Z","iopub.execute_input":"2024-05-18T03:21:52.715654Z","iopub.status.idle":"2024-05-18T03:21:52.726883Z","shell.execute_reply.started":"2024-05-18T03:21:52.715630Z","shell.execute_reply":"2024-05-18T03:21:52.725994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Discriminator model\ndef build_discriminator():\n    model = models.Sequential()\n    model.add(layers.Conv2D(64, kernel_size=5, strides=2, input_shape=(64, 64, 3), padding='same'))\n    model.add(layers.LeakyReLU(alpha=0.2))\n    model.add(layers.Dropout(0.4)) \n\n    model.add(layers.Conv2D(128, kernel_size=5, strides=2, padding='same'))\n    model.add(layers.BatchNormalization(momentum=0.9))\n    model.add(layers.LeakyReLU(alpha=0.2))\n    model.add(layers.Dropout(0.4))  \n\n    model.add(layers.Conv2D(256, kernel_size=5, strides=2, padding='same'))\n    model.add(layers.BatchNormalization(momentum=0.9))\n    model.add(layers.LeakyReLU(alpha=0.2))\n    model.add(layers.Dropout(0.4))  \n\n    model.add(layers.Conv2D(512, kernel_size=5, strides=2, padding='same'))\n    model.add(layers.BatchNormalization(momentum=0.9))\n    model.add(layers.LeakyReLU(alpha=0.2))\n    model.add(layers.Dropout(0.4))  \n    \n    model.add(layers.Flatten())\n    model.add(layers.Dense(1))\n    model.add(layers.Activation('sigmoid'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:21:52.728180Z","iopub.execute_input":"2024-05-18T03:21:52.728546Z","iopub.status.idle":"2024-05-18T03:21:52.740587Z","shell.execute_reply.started":"2024-05-18T03:21:52.728514Z","shell.execute_reply":"2024-05-18T03:21:52.739724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generator model\ndef build_generator():\n    model = models.Sequential()\n    model.add(layers.Dense(4*4*512,activation=\"relu\",input_dim=SEED_SIZE)) #64x64 units\n    model.add(layers.Reshape((4,4,512)))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU(alpha = 0.2))\n\n    model.add(layers.Conv2DTranspose(512, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU(alpha =0.3))\n\n    model.add(layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU(alpha = 0.2))\n\n    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU(alpha =0.3))\n    \n    model.add(layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False  ))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU(alpha = 0.2))\n\n    model.add(layers.Conv2DTranspose(IMAGE_CHANNELS, (5, 5), strides=(1, 1), padding='same', use_bias=True, activation='tanh'))\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:21:52.741835Z","iopub.execute_input":"2024-05-18T03:21:52.742194Z","iopub.status.idle":"2024-05-18T03:21:52.756008Z","shell.execute_reply.started":"2024-05-18T03:21:52.742162Z","shell.execute_reply":"2024-05-18T03:21:52.755017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generator loss\ndef generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:21:52.761338Z","iopub.execute_input":"2024-05-18T03:21:52.762360Z","iopub.status.idle":"2024-05-18T03:21:52.769131Z","shell.execute_reply.started":"2024-05-18T03:21:52.762326Z","shell.execute_reply":"2024-05-18T03:21:52.768114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Discriminator loss\ndef discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:21:52.770458Z","iopub.execute_input":"2024-05-18T03:21:52.771080Z","iopub.status.idle":"2024-05-18T03:21:52.778608Z","shell.execute_reply.started":"2024-05-18T03:21:52.771047Z","shell.execute_reply":"2024-05-18T03:21:52.777584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train step\ndef train_step(images):\n    noise = tf.random.normal([BATCH_SIZE, SEED_SIZE])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = generator(noise, training=True)\n\n        real_output = discriminator(images, training=True)\n        fake_output = discriminator(generated_images, training=True)\n\n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n\n    return gen_loss, disc_loss","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:21:52.779710Z","iopub.execute_input":"2024-05-18T03:21:52.780032Z","iopub.status.idle":"2024-05-18T03:21:52.789346Z","shell.execute_reply.started":"2024-05-18T03:21:52.780006Z","shell.execute_reply":"2024-05-18T03:21:52.788325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training loop\ndef train(dataset, epochs, checkpoint, checkpoint_prefix):\n    for epoch in range(epochs):\n        start = time.time()\n        for image_batch in dataset:\n            t =  train_step(image_batch)\n            gen_loss_list.append(t[0])\n            disc_loss_list.append(t[1])\n\n        g_loss = sum(gen_loss_list) / len(gen_loss_list)\n        d_loss = sum(disc_loss_list) / len(disc_loss_list)\n\n        if (epoch + 1) % SAVE_FREQ == 0:\n            save_images(epoch + 1, generator)\n            checkpoint.save(file_prefix=checkpoint_prefix)\n\n        print('Epoch {}, Generator Loss: {:.4f}, Discriminator Loss: {:.4f}, Time: {:.2f} sec'.format(epoch + 1, g_loss, d_loss, time.time()-start))\n        # Save the model \n    if epoch == EPOCHS - 1:\n        generator_file = '/kaggle/working/model/dcgan_generator.h5'\n        discriminator_file = '/kaggle/working/model/dcgan_discriminator.h5'\n        # Remove existing files if they exist\n        try:\n            os.remove(generator_file)\n            os.remove(discriminator_file)\n        except FileNotFoundError:\n            pass\n        os.makedirs('/kaggle/working/model', exist_ok=True)\n        # Lưu mô hình generator và discriminator\n        generator.save(generator_file)\n        discriminator.save(discriminator_file)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:21:52.790588Z","iopub.execute_input":"2024-05-18T03:21:52.791269Z","iopub.status.idle":"2024-05-18T03:21:52.802912Z","shell.execute_reply.started":"2024-05-18T03:21:52.791236Z","shell.execute_reply":"2024-05-18T03:21:52.802046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def save_images(epoch, generator):\n#     noise = tf.random.normal([16, NOISE_DIM])\n#     generated_images = generator(noise, training=False)\n\n#     fig = plt.figure(figsize=(4, 4))\n#     for i in range(generated_images.shape[0]):\n#         plt.subplot(4, 4, i+1)\n#         plt.imshow((generated_images[i] + 1) / 2)\n#         plt.axis('off')\n#     plt.savefig(f'generated_image_epoch_{epoch}.png')\n#     plt.close(fig)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:21:52.804046Z","iopub.execute_input":"2024-05-18T03:21:52.804688Z","iopub.status.idle":"2024-05-18T03:21:52.816073Z","shell.execute_reply.started":"2024-05-18T03:21:52.804652Z","shell.execute_reply":"2024-05-18T03:21:52.815149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_images(epoch, generator, output_dir=output_dir):\n    noise = tf.random.normal([16, NOISE_DIM])\n    generated_images = generator(noise, training=False)\n\n    fig = plt.figure(figsize=(10, 10))\n\n    for i in range(generated_images.shape[0]):\n        plt.subplot(4, 4, i+1)\n        plt.imshow(generated_images[i, :, :, :] * 0.5 + 0.5)\n        plt.axis('off')\n\n    plt.suptitle(f\"Generated Images - Epoch {epoch}\", fontsize=16)\n    plt.savefig(os.path.join(output_dir, f\"generated_images_epoch_{epoch}.png\"))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:21:52.817348Z","iopub.execute_input":"2024-05-18T03:21:52.817723Z","iopub.status.idle":"2024-05-18T03:21:52.826768Z","shell.execute_reply.started":"2024-05-18T03:21:52.817693Z","shell.execute_reply":"2024-05-18T03:21:52.825773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_generated_image(generator, seed_size):\n    # Create a random seed for generating new images\n    random_seed = tf.random.normal([1, seed_size])\n\n    # Generate an image using the generator\n    new_image = generator(random_seed, training=False)\n\n    # Convert the generated image to numpy array\n    generated_image = new_image.numpy()\n\n    # Rescale the pixel values to be between 0 and 255\n    generated_image = 0.5 * generated_image + 0.5\n    generated_image = (generated_image * 255).astype(np.uint8)\n\n    # Plot the generated image\n    plt.imshow(generated_image[0])\n    plt.axis('off')\n    plt.title('Generated Image')\n    plt.show()\n\n    return generated_image","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:21:52.828076Z","iopub.execute_input":"2024-05-18T03:21:52.828436Z","iopub.status.idle":"2024-05-18T03:21:52.840933Z","shell.execute_reply.started":"2024-05-18T03:21:52.828405Z","shell.execute_reply":"2024-05-18T03:21:52.840037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def classify_generated_image(discriminator, generated_image):\n    # Use the discriminator to classify the generated image\n    discriminator_output = discriminator.predict(generated_image)\n\n    # If the discriminator's output is closer to 1, then it's likely a real image\n    if discriminator_output >= 0.5:\n        print(\"The generated image is likely real.\")\n    else:\n        print(\"The generated image is likely fake.\")","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:21:52.842003Z","iopub.execute_input":"2024-05-18T03:21:52.842259Z","iopub.status.idle":"2024-05-18T03:21:52.850823Z","shell.execute_reply.started":"2024-05-18T03:21:52.842237Z","shell.execute_reply":"2024-05-18T03:21:52.849853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generator_path = '/kaggle/working/model/generator.h5'\n# if os.path.exists(generator_path):\n#     os.remove(generator_path)\n\n# discriminator_path = '/kaggle/working/model/discriminator.h5'\n# if os.path.exists(discriminator_path):\n#     os.remove(discriminator_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:21:52.852007Z","iopub.execute_input":"2024-05-18T03:21:52.852845Z","iopub.status.idle":"2024-05-18T03:21:52.859797Z","shell.execute_reply.started":"2024-05-18T03:21:52.852818Z","shell.execute_reply":"2024-05-18T03:21:52.858976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Optimizers\ngenerator_optimizer = Adam(1.5e-4, beta_1=0.5)\ndiscriminator_optimizer = Adam(1.5e-4, beta_1=0.5)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:21:52.860948Z","iopub.execute_input":"2024-05-18T03:21:52.861228Z","iopub.status.idle":"2024-05-18T03:21:53.515255Z","shell.execute_reply.started":"2024-05-18T03:21:52.861205Z","shell.execute_reply":"2024-05-18T03:21:53.514213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generator and discriminator models\ngenerator = build_generator()\ngenerator.compile(loss='binary_crossentropy', optimizer=generator_optimizer)\ngenerator.summary()","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:21:53.517364Z","iopub.execute_input":"2024-05-18T03:21:53.518103Z","iopub.status.idle":"2024-05-18T03:21:53.800329Z","shell.execute_reply.started":"2024-05-18T03:21:53.518068Z","shell.execute_reply":"2024-05-18T03:21:53.799286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator = build_discriminator()\ndiscriminator.compile(loss='binary_crossentropy', optimizer=discriminator_optimizer)\ndiscriminator.summary()","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:21:53.801372Z","iopub.execute_input":"2024-05-18T03:21:53.801675Z","iopub.status.idle":"2024-05-18T03:21:54.059259Z","shell.execute_reply.started":"2024-05-18T03:21:53.801649Z","shell.execute_reply":"2024-05-18T03:21:54.058266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load and preprocess data using tf.data.Dataset\ntraining_dataset = tf.data.Dataset.from_tensor_slices(training_data).shuffle(5000).batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:21:54.060395Z","iopub.execute_input":"2024-05-18T03:21:54.060675Z","iopub.status.idle":"2024-05-18T03:21:54.808300Z","shell.execute_reply.started":"2024-05-18T03:21:54.060651Z","shell.execute_reply":"2024-05-18T03:21:54.807321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_random_art(dataset):\n    # Shuffle the dataset\n    dataset = dataset.shuffle(buffer_size=len(dataset))\n\n    # Take a batch of images from the dataset\n    images = next(iter(dataset))\n\n    # Plot the images\n    fig = plt.figure(figsize=(12, 12))\n    for i in range(1, 37):\n        plt.subplot(6, 6, i)\n        plt.imshow(images[i])\n        plt.axis('off')\n    plt.show()\n\n\nvisualize_random_art(training_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:21:54.809721Z","iopub.execute_input":"2024-05-18T03:21:54.810050Z","iopub.status.idle":"2024-05-18T03:21:56.972148Z","shell.execute_reply.started":"2024-05-18T03:21:54.810024Z","shell.execute_reply":"2024-05-18T03:21:56.971133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir ./training_checkpoints\n# os.makedirs('/kaggle/working/training_checkpoints', exist_ok=True)\n# checkpoint\ncheckpoint_dir = './training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:21:56.973406Z","iopub.execute_input":"2024-05-18T03:21:56.973753Z","iopub.status.idle":"2024-05-18T03:21:58.073511Z","shell.execute_reply.started":"2024-05-18T03:21:56.973723Z","shell.execute_reply":"2024-05-18T03:21:58.072272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the GAN\ngen_loss_list = []\ndisc_loss_list = []\nos.makedirs(output_dir, exist_ok=True)\n# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\ntrain(training_dataset, EPOCHS, checkpoint, checkpoint_prefix)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:21:58.075421Z","iopub.execute_input":"2024-05-18T03:21:58.075860Z","iopub.status.idle":"2024-05-18T05:44:41.058472Z","shell.execute_reply.started":"2024-05-18T03:21:58.075821Z","shell.execute_reply":"2024-05-18T05:44:41.057616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot loss vs epoch\nplt.figure(figsize=(8, 6))\nplt.plot(range(len(gen_loss_list)), gen_loss_list, label='Generator Loss')\nplt.plot(range(len(disc_loss_list)), disc_loss_list, label='Discriminator Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('GAN Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-18T05:44:41.059642Z","iopub.execute_input":"2024-05-18T05:44:41.059941Z","iopub.status.idle":"2024-05-18T05:44:42.909053Z","shell.execute_reply.started":"2024-05-18T05:44:41.059916Z","shell.execute_reply":"2024-05-18T05:44:42.907930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_dir = \"/kaggle/working/output_model\"\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T05:44:42.910653Z","iopub.execute_input":"2024-05-18T05:44:42.911164Z","iopub.status.idle":"2024-05-18T05:44:42.916824Z","shell.execute_reply.started":"2024-05-18T05:44:42.911125Z","shell.execute_reply":"2024-05-18T05:44:42.915850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lưu kiến trúc mô hình dưới dạng JSON\nmodel_json = generator.to_json()\njson_path = os.path.join(output_dir, \"model_architecture.json\")\nwith open(json_path, \"w\") as json_file:\n    json_file.write(model_json)\n\n# Lưu trọng số mô hình\nweights_path = os.path.join(output_dir, \"model_weights.weights.h5\")\ngenerator.save_weights(weights_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T05:44:42.917977Z","iopub.execute_input":"2024-05-18T05:44:42.918280Z","iopub.status.idle":"2024-05-18T05:44:43.198416Z","shell.execute_reply.started":"2024-05-18T05:44:42.918250Z","shell.execute_reply":"2024-05-18T05:44:43.197325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = tf.keras.models.load_model('/kaggle/working/model/dcgan_generator.h5')\n# Display a generated image\ngenerated_image = display_generated_image(generator, SEED_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T05:44:43.199852Z","iopub.execute_input":"2024-05-18T05:44:43.200147Z","iopub.status.idle":"2024-05-18T05:44:44.037161Z","shell.execute_reply.started":"2024-05-18T05:44:43.200123Z","shell.execute_reply":"2024-05-18T05:44:44.036157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor i in range(1, 10):\n    generated_image = display_generated_image(generator, SEED_SIZE)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-18T05:44:44.038707Z","iopub.execute_input":"2024-05-18T05:44:44.039108Z","iopub.status.idle":"2024-05-18T05:44:45.253211Z","shell.execute_reply.started":"2024-05-18T05:44:44.039072Z","shell.execute_reply":"2024-05-18T05:44:45.251769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator = tf.keras.models.load_model('/kaggle/working/model/dcgan_discriminator.h5')\n# Classify a generated image\nclassify_generated_image(discriminator, generated_image)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T05:44:45.254893Z","iopub.execute_input":"2024-05-18T05:44:45.255407Z","iopub.status.idle":"2024-05-18T05:44:46.674764Z","shell.execute_reply.started":"2024-05-18T05:44:45.255370Z","shell.execute_reply":"2024-05-18T05:44:46.673642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nimport cv2\nfrom scipy.linalg import sqrtm\n# from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\nfrom PIL import Image\nimport keras\nfrom keras.applications.inception_v3 import InceptionV3, preprocess_input","metadata":{"execution":{"iopub.status.busy":"2024-05-18T05:44:46.676820Z","iopub.execute_input":"2024-05-18T05:44:46.677271Z","iopub.status.idle":"2024-05-18T05:44:46.871688Z","shell.execute_reply.started":"2024-05-18T05:44:46.677234Z","shell.execute_reply":"2024-05-18T05:44:46.870726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_images(images):\n    images_resized = np.array([np.array(Image\n                                        .fromarray((img * 255)\n                                        .astype(np.uint8))\n                                        .resize((299, 299))) for img in images])\n    images_preprocessed = preprocess_input(images_resized)\n    return images_preprocessed","metadata":{"execution":{"iopub.status.busy":"2024-05-18T05:44:46.872927Z","iopub.execute_input":"2024-05-18T05:44:46.873230Z","iopub.status.idle":"2024-05-18T05:44:46.879578Z","shell.execute_reply.started":"2024-05-18T05:44:46.873203Z","shell.execute_reply":"2024-05-18T05:44:46.878444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inception_score(images, batch_size=32):\n    inception_model = InceptionV3(include_top=True, weights='imagenet')\n    processed_images = preprocess_images(images)\n    preds = inception_model.predict(processed_images, batch_size=batch_size)\n    preds = np.exp(preds) / np.sum(np.exp(preds), axis=1, keepdims=True)\n    scores = np.sum(preds * np.log(preds), axis=1)\n    scores = np.exp(np.mean(scores))\n    return scores","metadata":{"execution":{"iopub.status.busy":"2024-05-18T05:44:46.886594Z","iopub.execute_input":"2024-05-18T05:44:46.886922Z","iopub.status.idle":"2024-05-18T05:44:46.893908Z","shell.execute_reply.started":"2024-05-18T05:44:46.886896Z","shell.execute_reply":"2024-05-18T05:44:46.892861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_fid(real_images, generated_images):\n    inception_model = InceptionV3(include_top=False, pooling='avg', input_shape=(299, 299, 3))\n    real_images = preprocess_images(real_images)\n    generated_images = preprocess_images(generated_images)\n    real_activations = inception_model.predict(real_images)\n    generated_activations = inception_model.predict(generated_images)\n    mu_real, sigma_real = np.mean(real_activations, axis=0), np.cov(real_activations, rowvar=False)\n    mu_gen, sigma_gen = np.mean(generated_activations, axis=0), np.cov(generated_activations, rowvar=False)\n    diff_mean = np.sum((mu_real - mu_gen)**2)\n    cov_mean = sqrtm(sigma_real.dot(sigma_gen))\n    if np.iscomplexobj(cov_mean):\n        cov_mean = cov_mean.real\n    fid = diff_mean + np.trace(sigma_real + sigma_gen - 2*cov_mean)\n    return fid","metadata":{"execution":{"iopub.status.busy":"2024-05-18T05:44:46.895337Z","iopub.execute_input":"2024-05-18T05:44:46.895748Z","iopub.status.idle":"2024-05-18T05:44:46.905645Z","shell.execute_reply.started":"2024-05-18T05:44:46.895714Z","shell.execute_reply":"2024-05-18T05:44:46.904594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_fake_samples(generator, seed_size, n_samples):\n    generated_images = []\n    for _ in range(n_samples):\n        random_seed = tf.random.normal([1, seed_size])\n        new_image = generator(random_seed, training=False)\n        generated_images.append(new_image[0].numpy())\n    return generated_images","metadata":{"execution":{"iopub.status.busy":"2024-05-18T05:44:46.906964Z","iopub.execute_input":"2024-05-18T05:44:46.907380Z","iopub.status.idle":"2024-05-18T05:44:46.918337Z","shell.execute_reply.started":"2024-05-18T05:44:46.907344Z","shell.execute_reply":"2024-05-18T05:44:46.917353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_GAN(generator, seed_size, n_samples, real_images):\n    fake_samples = generate_fake_samples(generator, seed_size, n_samples)\n    score = inception_score(fake_samples)\n    fid = calculate_fid(real_images, fake_samples)\n    return score, fid","metadata":{"execution":{"iopub.status.busy":"2024-05-18T05:44:46.919801Z","iopub.execute_input":"2024-05-18T05:44:46.920155Z","iopub.status.idle":"2024-05-18T05:44:46.928460Z","shell.execute_reply.started":"2024-05-18T05:44:46.920131Z","shell.execute_reply":"2024-05-18T05:44:46.927596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_images_from_directory(image_dir):\n    images = []\n    count = 0\n    for filename in os.listdir(image_dir):\n        if count >= 150:  # Số lượng ảnh tối đa\n            break\n        img_path = os.path.join(image_dir, filename)\n        if os.path.isfile(img_path):\n            img = cv2.imread(img_path)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Chuyển đổi từ BGR sang RGB\n            img = img / 255.0  # Chuẩn hóa giá trị ảnh từ 0-255 về 0-1\n            images.append(img)\n            count += 1\n    return images","metadata":{"execution":{"iopub.status.busy":"2024-05-18T05:44:46.929768Z","iopub.execute_input":"2024-05-18T05:44:46.930398Z","iopub.status.idle":"2024-05-18T05:44:46.937517Z","shell.execute_reply.started":"2024-05-18T05:44:46.930366Z","shell.execute_reply":"2024-05-18T05:44:46.936776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_image_dir = \"../input/wikiart/Realism\"\nn_samples = 150\nreal_images = load_images_from_directory(validation_image_dir)\nscore, fid = evaluate_GAN(generator, SEED_SIZE, n_samples, real_images)\nprint(\"Inception Score:\", score)\nprint(\"Fréchet Inception Distance:\", fid)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T05:44:46.939382Z","iopub.execute_input":"2024-05-18T05:44:46.939716Z","iopub.status.idle":"2024-05-18T05:46:09.043861Z","shell.execute_reply.started":"2024-05-18T05:44:46.939691Z","shell.execute_reply":"2024-05-18T05:46:09.042410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = \"/kaggle/input/dcgan_model/tensorflow2/dcganggenerator/1/dcgan_generator.keras\"\nreload_model = tf.keras.models.load_model(model_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T05:46:09.046110Z","iopub.execute_input":"2024-05-18T05:46:09.047008Z","iopub.status.idle":"2024-05-18T05:46:10.800684Z","shell.execute_reply.started":"2024-05-18T05:46:09.046956Z","shell.execute_reply":"2024-05-18T05:46:10.799764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(1, 10):\n    generated_image = display_generated_image(generator, SEED_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T05:46:10.801901Z","iopub.execute_input":"2024-05-18T05:46:10.802221Z","iopub.status.idle":"2024-05-18T05:46:12.522738Z","shell.execute_reply.started":"2024-05-18T05:46:10.802195Z","shell.execute_reply":"2024-05-18T05:46:12.521794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_dir = \"/kaggle/working/output_model\"\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T05:46:12.524161Z","iopub.execute_input":"2024-05-18T05:46:12.524527Z","iopub.status.idle":"2024-05-18T05:46:12.529802Z","shell.execute_reply.started":"2024-05-18T05:46:12.524494Z","shell.execute_reply":"2024-05-18T05:46:12.528740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lưu kiến trúc mô hình dưới dạng JSON\nmodel_json = reload_model.to_json()\njson_path = os.path.join(output_dir, \"model_architecture.json\")\nwith open(json_path, \"w\") as json_file:\n    json_file.write(model_json)\n\n# Lưu trọng số mô hình\nweights_path = os.path.join(output_dir, \"model_weights.weights.h5\")\nreload_model.save_weights(weights_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T05:46:12.531183Z","iopub.execute_input":"2024-05-18T05:46:12.531607Z","iopub.status.idle":"2024-05-18T05:46:12.722520Z","shell.execute_reply.started":"2024-05-18T05:46:12.531555Z","shell.execute_reply":"2024-05-18T05:46:12.721635Z"},"trusted":true},"execution_count":null,"outputs":[]}]}